{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs0//gEN2Hg5T5QNNAqTAX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prince0906/Demo-repository/blob/main/GENAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "3T4sqK4y3KlC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "OPENAI_API_BASE_URL = \"https://api.openai.com/v1\"\n",
        "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
        "TEXT_MODEL_ENGINE = 'gpt-3.5-turbo-16k'\n",
        "\n",
        "def create_open_ai_query(input_query, system_message=None, model_engine=TEXT_MODEL_ENGINE,\n",
        "                         functions=None, function_call=None, temperature=0.5, max_tokens=None):\n",
        "    openai_url = f\"{OPENAI_API_BASE_URL}/chat/completions\"\n",
        "    headers = {'Authorization': f'Bearer {OPENAI_API_KEY}', 'Content-Type': 'application/json'}\n",
        "    messages = []\n",
        "    if system_message:\n",
        "      messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "    messages.append({\"role\": \"user\", \"content\": input_query})\n",
        "    payload = {\n",
        "        'model': model_engine,\n",
        "        'messages': messages,\n",
        "        'temperature': temperature\n",
        "    }\n",
        "    if functions:\n",
        "      payload['functions'] = functions\n",
        "      payload['function_call'] = function_call\n",
        "\n",
        "    if max_tokens:\n",
        "      payload['max_tokens'] = max_tokens\n",
        "\n",
        "    response = requests.post(openai_url, headers=headers, data=json.dumps(payload))\n",
        "    if response.status_code == 200 and 'choices' in response.json():\n",
        "        if functions:\n",
        "            content_text = response.json()['choices'][0]['message']['function_call']['arguments'].strip()\n",
        "        else:\n",
        "            content_text = response.json()['choices'][0]['message']['content'].strip()\n",
        "        return {\"success\": True, \"data\": content_text, \"response_json\": response.json()}\n",
        "    return {\"success\": False, \"error\": response.text}"
      ],
      "metadata": {
        "id": "y9sr4WUmG6rs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_open_ai_query(\"hey\")['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MITx9FLSJRnv",
        "outputId": "a7b3325f-8282-4a51-dae3-d9dd4cc1955b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_open_ai_query('22 + 44 =')['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ajuMpcnjJ0MU",
        "outputId": "859580a5-037a-405d-9138-4d5f0a5a056c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'66'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_open_ai_query('the sky is')['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J992e6neKaUY",
        "outputId": "497b8f39-60df-40c2-b44e-c88a3a9087af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blue.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_open_ai_query('the sky is')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWpzv9DcKt2I",
        "outputId": "07ba513e-b6f8-40c1-c8bf-caee6cd251d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'data': 'blue.',\n",
              " 'response_json': {'id': 'chatcmpl-8vlozjYAXmWYDyDFYsbWLO1sdDiGV',\n",
              "  'object': 'chat.completion',\n",
              "  'created': 1708779213,\n",
              "  'model': 'gpt-3.5-turbo-16k-0613',\n",
              "  'choices': [{'index': 0,\n",
              "    'message': {'role': 'assistant', 'content': 'blue.'},\n",
              "    'logprobs': None,\n",
              "    'finish_reason': 'stop'}],\n",
              "  'usage': {'prompt_tokens': 10, 'completion_tokens': 2, 'total_tokens': 12},\n",
              "  'system_fingerprint': None}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Q: What is prompt engineer\"\n",
        "create_open_ai_query(prompt)['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "zqC1xRfjLbVY",
        "outputId": "f4146ec9-1d61-43e4-8eb8-9372edee88bf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A: \"Prompt engineer\" is not a commonly used term or job title. It could refer to someone who specializes in creating prompts or cues for specific tasks or activities. For example, in the field of human-computer interaction, a prompt engineer may design prompts or notifications that guide users through a software application or system. However, without further context, it is difficult to determine the exact meaning or role of a \"prompt engineer.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Classify the text into neutral, negative, or positive\n",
        "Text: I think the food was okay\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "create_open_ai_query(prompt)['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HJNMU6w4MHSi",
        "outputId": "4657025d-5671-4e69-cce1-4393c4ce7ed9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "###Instruction###\n",
        "Please note that the time limit for this problem is only 0.5 seconds per test.\n",
        "\n",
        "Vladislav wrote the integers from 1\n",
        " to ùëõ\n",
        ", inclusive, on the board. Then he replaced each integer with the sum of its digits.\n",
        "\n",
        "What is the sum of the numbers on the board now?\n",
        "\n",
        "For example, if ùëõ=12\n",
        " then initially the numbers on the board are:\n",
        "1,2,3,4,5,6,7,8,9,10,11,12.\n",
        "Then after the replacement, the numbers become:\n",
        "1,2,3,4,5,6,7,8,9,1,2,3.\n",
        "The sum of these numbers is 1+2+3+4+5+6+7+8+9+1+2+3=51\n",
        ". Thus, for ùëõ=12\n",
        " the answer is 51\n",
        ".\n",
        "\n",
        "Input\n",
        "The first line contains an integer ùë°\n",
        " (1‚â§ùë°‚â§104\n",
        ") ‚Äî the number of test cases.\n",
        "\n",
        "The only line of each test case contains a single integer ùëõ\n",
        " (1‚â§ùëõ‚â§2‚ãÖ105\n",
        ") ‚Äî the largest number Vladislav writes.\n",
        "\n",
        "Output\n",
        "For each test case, output a single integer ‚Äî the sum of the numbers at the end of the process.\n",
        "Example:\n",
        "input\n",
        "12\n",
        "\n",
        "output\n",
        "51\n",
        "\n",
        "explanation\n",
        "Initial: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n",
        "After changing: 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3\n",
        "\n",
        "Summing them all gives 51.\n",
        "\"\"\"\n",
        "create_open_ai_query(prompt)['data']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "skv3oKWXPL5Z",
        "outputId": "587f16da-404e-4899-bfe0-c105bd1309de"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To solve this problem, we can iterate through each number from 1 to n and calculate the sum of its digits. We can then add this sum to a running total. Finally, we return the total sum.\\n\\nHere is the implementation in Python:\\n\\n```python\\nt = int(input()) # number of test cases\\n\\nfor _ in range(t):\\n    n = int(input()) # largest number Vladislav writes\\n    total_sum = 0\\n    \\n    for i in range(1, n+1):\\n        digit_sum = sum(int(digit) for digit in str(i)) # calculate the sum of digits\\n        total_sum += digit_sum\\n    \\n    print(total_sum)\\n```\\n\\nThis solution has a time complexity of O(n log n), where n is the largest number Vladislav writes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "JSON_FORMAT = {\n",
        "  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "\n",
        "      \"date\": {\n",
        "        \"type\": \"string\",\n",
        "        \"format\": \"date\",\n",
        "        \"description\": \"Date in the format 'YYYY-MM-DD'.\"\n",
        "      },\n",
        "      \"activites\": {\n",
        "        \"type\": \"array\",\n",
        "        \"items\": {\n",
        "          \"type\": \"object\",\n",
        "          \"properties\": {\n",
        "            \"Serial no\": {\n",
        "              \"type\": \"integer\",\n",
        "              \"description\": \"Serial number of the activity.\"\n",
        "            },\n",
        "            \"Time\": {\n",
        "              \"type\": \"string\",\n",
        "              \"format\": \"time\",\n",
        "              \"description\": \"Time in the format 'HH:mm'.\"\n",
        "            },\n",
        "            \"food\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Type of food for the activity.\"\n",
        "            },\n",
        "            \"location\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Location of the activity.\"\n",
        "            },\n",
        "            \"price\": {\n",
        "              \"type\": \"number\",\n",
        "              \"description\": \"Price associated with the activity.\"\n",
        "            },\n",
        "            \"duration\": {\n",
        "                \"type\": \"string\",\n",
        "            },\n",
        "            \"message\": {\n",
        "              \"type\": \"string\",\n",
        "              \"description\": \"Additional message for the activity.\"\n",
        "            }\n",
        "          },\n",
        "          \"required\": [\"Serial no\", \"Time\", \"food\", \"location\", \"price\", \"message\"],\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"date\", \"activites\"],\n",
        "  }\n",
        "functions = [{\"name\": \"final_json\", \"parameters\": JSON_FORMAT}]\n",
        "function_call = {\"name\": \"final_json\"}\n",
        "prompt = \"I want to travel to hyderabad for the duration of 3 days which will start on 25/02/2023. The trip should be of partying mood and low budget so decide price by your own according to low budget.At the end write the additional ending message according to the trip mood\"\n",
        "system_message = \"I want you to act as a trip system planner which decides the whole trip plan and the trip timing must be of morning and then lunch and then evening and then night . You also decide food according to that time and must give data according to the duration of the days\"\n",
        "resp = create_open_ai_query(prompt, system_message=system_message, functions = functions, function_call = function_call)\n",
        "print(resp)\n",
        "print(type(resp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Ep59haTytv",
        "outputId": "0497d57d-5897-4a5b-f9d2-77b9ab7a94a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'success': True, 'data': '{\\n  \"date\": \"2023-02-25\",\\n  \"activites\": [\\n    {\\n      \"Serial no\": 1,\\n      \"Time\": \"Morning\",\\n      \"food\": \"Breakfast\",\\n      \"location\": \"Beach Shack\",\\n      \"price\": 100,\\n      \"message\": \"Start your day with a delicious breakfast at a beach shack to energize yourself for the day ahead.\"\\n    },\\n    {\\n      \"Serial no\": 2,\\n      \"Time\": \"Lunch\",\\n      \"food\": \"Seafood\",\\n      \"location\": \"Fisherman\\'s Wharf\",\\n      \"price\": 200,\\n      \"message\": \"Enjoy a scrumptious seafood lunch at Fisherman\\'s Wharf, known for its fresh catch and vibrant atmosphere.\"\\n    },\\n    {\\n      \"Serial no\": 3,\\n      \"Time\": \"Evening\",\\n      \"food\": \"Street Food\",\\n      \"location\": \"Anjuna Night Market\",\\n      \"price\": 50,\\n      \"message\": \"Explore the bustling Anjuna Night Market and indulge in the local street food delicacies.\"\\n    },\\n    {\\n      \"Serial no\": 4,\\n      \"Time\": \"Night\",\\n      \"food\": \"Goan Thali\",\\n      \"location\": \"Taverna Panjim\",\\n      \"price\": 150,\\n      \"message\": \"End your day with a traditional Goan Thali dinner at Taverna Panjim, known for its authentic Goan cuisine.\"\\n    }\\n  ]\\n}', 'response_json': {'id': 'chatcmpl-8w246mFdD4wkJ8KAZTmqjvo6CsS2v', 'object': 'chat.completion', 'created': 1708841654, 'model': 'gpt-3.5-turbo-16k-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': None, 'function_call': {'name': 'final_json', 'arguments': '{\\n  \"date\": \"2023-02-25\",\\n  \"activites\": [\\n    {\\n      \"Serial no\": 1,\\n      \"Time\": \"Morning\",\\n      \"food\": \"Breakfast\",\\n      \"location\": \"Beach Shack\",\\n      \"price\": 100,\\n      \"message\": \"Start your day with a delicious breakfast at a beach shack to energize yourself for the day ahead.\"\\n    },\\n    {\\n      \"Serial no\": 2,\\n      \"Time\": \"Lunch\",\\n      \"food\": \"Seafood\",\\n      \"location\": \"Fisherman\\'s Wharf\",\\n      \"price\": 200,\\n      \"message\": \"Enjoy a scrumptious seafood lunch at Fisherman\\'s Wharf, known for its fresh catch and vibrant atmosphere.\"\\n    },\\n    {\\n      \"Serial no\": 3,\\n      \"Time\": \"Evening\",\\n      \"food\": \"Street Food\",\\n      \"location\": \"Anjuna Night Market\",\\n      \"price\": 50,\\n      \"message\": \"Explore the bustling Anjuna Night Market and indulge in the local street food delicacies.\"\\n    },\\n    {\\n      \"Serial no\": 4,\\n      \"Time\": \"Night\",\\n      \"food\": \"Goan Thali\",\\n      \"location\": \"Taverna Panjim\",\\n      \"price\": 150,\\n      \"message\": \"End your day with a traditional Goan Thali dinner at Taverna Panjim, known for its authentic Goan cuisine.\"\\n    }\\n  ]\\n}'}}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 204, 'completion_tokens': 312, 'total_tokens': 516}, 'system_fingerprint': None}}\n",
            "<class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--UmPLGb3GkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}